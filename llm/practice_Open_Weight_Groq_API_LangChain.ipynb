{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOmZwsI1kTrd"
   },
   "source": [
    "#### 다음 실습 코드는 학습 목적으로만 사용 바랍니다. 문의 : audit@korea.ac.kr 임성열 Ph.D.\n",
    "\n",
    "Groq의 빠른 추론 엔진을 LangChain에서 체험하는 코드를 소개합니다.    \n",
    "langchain_groq를 통해 쉽게 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "id": "daSSN5ZSetZl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_groq in .\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: pymupdf in .\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: pypdf in .\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: requests in .\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: langchain==0.1.14 in .\\lib\\site-packages (0.1.14)\n",
      "Requirement already satisfied: langchain_community==0.0.30 in .\\lib\\site-packages (0.0.30)\n",
      "Collecting openai==1.25.1\n",
      "  Using cached openai-1.25.1-py3-none-any.whl (312 kB)\n",
      "Requirement already satisfied: python-dotenv in .\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in .\\lib\\site-packages (from langchain==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\lib\\site-packages (from langchain==0.1.14) (3.12.15)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\lib\\site-packages (from langchain==0.1.14) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in .\\lib\\site-packages (from langchain==0.1.14) (0.1.53)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\lib\\site-packages (from langchain==0.1.14) (8.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in .\\lib\\site-packages (from langchain==0.1.14) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in .\\lib\\site-packages (from langchain==0.1.14) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in .\\lib\\site-packages (from langchain==0.1.14) (0.1.147)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\lib\\site-packages (from langchain==0.1.14) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\lib\\site-packages (from langchain==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\lib\\site-packages (from langchain==0.1.14) (2.11.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in .\\lib\\site-packages (from langchain==0.1.14) (1.26.4)\n",
      "Requirement already satisfied: tqdm>4 in .\\lib\\site-packages (from openai==1.25.1) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\lib\\site-packages (from openai==1.25.1) (4.10.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in .\\lib\\site-packages (from openai==1.25.1) (4.14.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\lib\\site-packages (from openai==1.25.1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\lib\\site-packages (from openai==1.25.1) (0.28.1)\n",
      "Requirement already satisfied: sniffio in .\\lib\\site-packages (from openai==1.25.1) (1.3.1)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in .\\lib\\site-packages (from langchain_groq) (0.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.6.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.20.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (0.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.25.1) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in .\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.25.1) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in .\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.25.1) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in .\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14) (23.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.11.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in .\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in .\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.2.4)\n",
      "Requirement already satisfied: colorama in .\\lib\\site-packages (from tqdm>4->openai==1.25.1) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.1.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.99.9\n",
      "    Uninstalling openai-1.99.9:\n",
      "      Successfully uninstalled openai-1.99.9\n",
      "Successfully installed openai-1.25.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Agent처럼 별도 다른 버전으로 맞춘 패키지를 별도 가상 환경에서 동작시키기 위한 예시 (다음 코드는 최신 버전에서도 정상 동작함)\n",
    "# 일반적으로 최신 버전으로 지정해야 정상 처리되나, 특정 헤비한 패키지인 경우 하위 버전 종속성 가짐 (예, Crew AI, TensorFlow, PyTorch 등) \n",
    "!pip install langchain_groq pymupdf pypdf beautifulsoup4 requests \\\n",
    "            langchain==0.1.14 \\\n",
    "            langchain_community==0.0.30 \\\n",
    "            openai==1.25.1 \\\n",
    "            python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo6qR14UoZEu"
   },
   "source": [
    "현재 사용 가능한 주요 모델과 API 제한은 아래와 같습니다.\n",
    "\n",
    "\n",
    "| ID                                     | Requests per Minute | Requests per Day | Tokens per Minute | Tokens per Day |\n",
    "|----------------------------------------|---------------------|------------------|-------------------|----------------|\n",
    "| gemma-7b-it                            | 30                  | 14,400           | 15,000            | 500,000        |\n",
    "| gemma2-9b-it                           | 30                  | 14,400           | 15,000            | 500,000        |\n",
    "| llama-3.1-70b-versatile                | 30                  | 14,400           | 18,000            | 500,000        |\n",
    "| llama-3.1-8b-instant                   | 30                  | 14,400           | 20,000            | 500,000        |\n",
    "| llama-3.2-11b-text-preview             | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-11b-vision-preview           | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-1b-preview                   | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-3b-preview                   | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-90b-text-preview             | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-90b-vision-preview           | 15                  | 3,500            | 7,000             | 250,000        |\n",
    "| llava-v1.5-7b-4096-preview             | 30                  | 14,400           | 30,000            | (No limit)     |\n",
    "| mixtral-8x7b-32768                     | 30                  | 14,400           | 5,000             | 500,000        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZozwH3G_kPDc"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # Groq-LangChain 연결\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcNUf5TCpZTe"
   },
   "source": [
    "간단한 체인을 만들고 실행합니다.\n",
    "\n",
    "https://console.groq.com/keys 에서 키를 생성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NVj9S2kZeThO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 답변:\n",
      " Groq 엔진의 LLM 추론 속도가 빠른 이유는 compute density, memory bandwidth, and scalability를 최적화하여 GPU의 추론 속도 제한을 뛰어넘는 LPUs(Lookup Processing Units) 때문입니다. LPUs는 inference computing을 위한 새로운 접근 방식을 사용하여, energy efficiency도 10배 이상 높을 수 있습니다.\n",
      "\n",
      "⏱️ 처리 시간: 0.44초\n"
     ]
    }
   ],
   "source": [
    "# .env 파일 불러오기\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 환경변수로 Groq API Key 설정\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\", \"여기에_본인_KEY를_입력하세요\")\n",
    "\n",
    "# Groq Chat 모델 설정 (텍스트 전용 작업에는 llama3-8b-8192 등 사용 권장)\n",
    "chat = ChatGroq(\n",
    "    temperature=0.1,\n",
    "    model=\"llama3-8b-8192\",  # 또는 \"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "# 웹 페이지 로드\n",
    "url = \"https://wow.groq.com/why-groq/\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# 예외 처리: 문서가 없을 경우 중단\n",
    "if not docs:\n",
    "    raise ValueError(\"❗ 문서 로드 실패: 페이지에서 내용을 불러올 수 없습니다.\")\n",
    "\n",
    "# 질문 및 프롬프트 구성\n",
    "question = \"Groq 엔진의 LLM 추론 속도가 빠른 이유는 무엇인가요? 한국어로 답변하세요.\"\n",
    "\n",
    "system = \"Answer the question from given contexts. Answer in Korean.\"\n",
    "human = \"\"\"\n",
    "Context: {context}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# 체인 구성\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "chain = prompt | chat | StrOutputParser()\n",
    "\n",
    "# 실행 및 출력\n",
    "start = time.time()\n",
    "result = chain.invoke({\n",
    "    \"context\": docs[0].page_content,\n",
    "    \"question\": question\n",
    "})\n",
    "print(\"🔹 답변:\\n\", result)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\n⏱️ 처리 시간: {end - start:.2f}초\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyM4Yt-fMpoX"
   },
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4F1k171MpoY"
   },
   "source": [
    "요약은 LLM의 아주 중요한 기능 중 하나입니다.   \n",
    "일반적으로, LLM의 Abstractive Summarization은 3개의 방법을 사용합니다.\n",
    "\n",
    "- Stuff : 전체 코퍼스를 하나의 프롬프트에 넣고 요약 생성하기\n",
    "- Map-Reduce : 코퍼스를 청크로 분리하고, 각 청크의 요약을 생성한 뒤 합치기\n",
    "- Refine: 코퍼스를 청크로 분리하고, 순차적으로 읽으며 요약 업데이트하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9vkYtYkMpoa"
   },
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUemn2D7ikKc"
   },
   "source": [
    "gemma 2 모델을 이용해 요약을 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kMmlgYzWMpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Summarize the following paper in Korean.\\nEmphasize the uniqueness and contribution of the paper.\\nAnswer should be in 10 sentences.\\nPlease Answer in Korean.\\n'),\n",
       " HumanMessage(content=\"\\n\\n [1706.03762] Attention Is All You Need\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\\nDonate\\n\\n\\n\\n\\n\\n > cs > arXiv:1706.03762\\n  \\n\\n\\n\\n\\n\\nHelp | Advanced Search\\n\\n\\n\\n\\nAll fields\\nTitle\\nAuthor\\nAbstract\\nComments\\nJournal reference\\nACM classification\\nMSC classification\\nReport number\\narXiv identifier\\nDOI\\nORCID\\narXiv author ID\\nHelp pages\\nFull text\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nopen search\\n\\n\\n\\n\\n\\n\\nGO\\n\\n\\n\\nopen navigation menu\\n\\n\\nquick links\\n\\nLogin\\nHelp Pages\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Science > Computation and Language\\n\\n\\narXiv:1706.03762 (cs)\\n    \\n\\n\\n\\n\\n  [Submitted on 12 Jun 2017 (v1), last revised 2 Aug 2023 (this version, v7)]\\nTitle:Attention Is All You Need\\nAuthors:Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\\nView PDF\\nHTML (experimental)\\n\\nAbstract:The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\\n    \\n\\n\\n \\nComments:\\n15 pages, 5 figures\\n\\n\\nSubjects:\\n\\nComputation and Language (cs.CL); Machine Learning (cs.LG)\\n\\nCite as:\\narXiv:1706.03762 [cs.CL]\\n\\n\\n\\xa0\\n(or \\narXiv:1706.03762v7 [cs.CL] for this version)\\n          \\n\\n\\n\\xa0\\n https://doi.org/10.48550/arXiv.1706.03762\\n\\n\\nFocus to learn more\\n\\n\\n\\n                  arXiv-issued DOI via DataCite\\n\\n\\n\\n\\n\\n\\n\\nSubmission history From: Llion Jones [view email]       [v1]\\n        Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)\\n[v2]\\n        Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)\\n[v3]\\n        Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)\\n[v4]\\n        Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)\\n[v5]\\n        Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)\\n[v6]\\n        Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)\\n[v7]\\n        Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)\\n\\n\\n\\n \\n\\nFull-text links:\\nAccess Paper:\\n\\n\\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authorsView PDFHTML (experimental)TeX SourceOther Formats\\nview license\\n\\n \\n    Current browse context: cs.CL\\n\\n\\n<\\xa0prev\\n\\n\\xa0 | \\xa0 \\nnext\\xa0>\\n\\n\\nnew\\n | \\nrecent\\n | 2017-06\\n\\n    Change to browse by:\\n    \\ncs\\ncs.LG\\n\\n\\n\\n\\nReferences & Citations\\n\\nNASA ADSGoogle Scholar\\nSemantic Scholar\\n\\n\\n\\n\\n\\n 123 blog links (what is this?)\\n        \\n\\n\\nDBLP - CS Bibliography\\n\\nlisting | bibtex \\n\\nAshish VaswaniNoam ShazeerNiki ParmarJakob UszkoreitLlion Jones …\\n\\n\\na\\nexport BibTeX citation\\nLoading...\\n\\n\\n\\n\\nBibTeX formatted citation\\n×\\n\\n\\nloading...\\n\\n\\nData provided by: \\n\\n\\n\\n\\nBookmark\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBibliographic Tools\\n\\nBibliographic and Citation Tools\\n\\n\\n\\n\\n\\n\\nBibliographic Explorer Toggle\\n\\n\\n\\nBibliographic Explorer (What is the Explorer?)\\n\\n\\n\\n\\n\\n\\n\\nConnected Papers Toggle\\n\\n\\n\\nConnected Papers (What is Connected Papers?)\\n\\n\\n\\n\\n\\n\\nLitmaps Toggle\\n\\n\\n\\nLitmaps (What is Litmaps?)\\n\\n\\n\\n\\n\\n\\n\\nscite.ai Toggle\\n\\n\\n\\nscite Smart Citations (What are Smart Citations?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode, Data, Media\\n\\nCode, Data and Media Associated with this Article\\n\\n\\n\\n\\n\\n\\nalphaXiv Toggle\\n\\n\\n\\nalphaXiv (What is alphaXiv?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\\n\\n\\n\\n\\n\\n\\n\\nDagsHub Toggle\\n\\n\\n\\nDagsHub (What is DagsHub?)\\n\\n\\n\\n\\n\\n\\n\\nGotitPub Toggle\\n\\n\\n\\nGotit.pub (What is GotitPub?)\\n\\n\\n\\n\\n\\n\\n\\nHuggingface Toggle\\n\\n\\n\\nHugging Face (What is Huggingface?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nPapers with Code (What is Papers with Code?)\\n\\n\\n\\n\\n\\n\\n\\nScienceCast Toggle\\n\\n\\n\\nScienceCast (What is ScienceCast?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDemos\\n\\nDemos\\n\\n\\n\\n\\n\\n\\nReplicate Toggle\\n\\n\\n\\nReplicate (What is Replicate?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nHugging Face Spaces (What is Spaces?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nTXYZ.AI (What is TXYZ.AI?)\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Papers\\n\\nRecommenders and Search Tools\\n\\n\\n\\n\\n\\n\\nLink to Influence Flower\\n\\n\\n\\nInfluence Flower (What are Influence Flowers?)\\n\\n\\n\\n\\n\\n\\n\\nCore recommender toggle\\n\\n\\n\\nCORE Recommender (What is CORE?)\\n\\n\\n\\n\\n\\nAuthor\\nVenue\\nInstitution\\nTopic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        About arXivLabs\\n      \\n\\n\\n\\narXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich authors of this paper are endorsers? |\\n    Disable MathJax (What is MathJax?)\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\nHelp\\n\\n\\n\\n\\n\\ncontact arXivClick here to contact arXiv\\n Contact\\n\\n\\nsubscribe to arXiv mailingsClick here to subscribe\\n Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright\\nPrivacy Policy\\n\\n\\n\\n\\nWeb Accessibility Assistance\\n\\n\\narXiv Operational Status \\n                    Get status notifications via\\n                    email\\n                    or slack\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stuff\n",
    "example_URL='https://arxiv.org/abs/1706.03762'\n",
    "\n",
    "loader = WebBaseLoader(example_URL)\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "gemma2 = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=\"gemma2-9b-it\",\n",
    ")\n",
    "\n",
    "summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Summarize the following paper in Korean.\n",
    "Emphasize the uniqueness and contribution of the paper.\n",
    "Answer should be in 10 sentences.\n",
    "Please Answer in Korean.\n",
    "'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "print(len(docs[0].page_content))\n",
    "summarize_prompt.format_messages(text=docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5MOx1k71Mpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문 \"Attention Is All You Need\"는 순환 신경망이나 합성곱 신경망과 같은 복잡한 구조를 사용하지 않고, **단순히 Attention 메커니즘만을 기반으로** 기존의 기계 번역 모델을 뛰어넘는 성능을 보여주는 새로운 네트워크 아키텍처인 Transformer를 제안합니다. \n",
      "\n",
      "이 논문의 가장 큰 혁신은 **RNN이나 CNN을 사용하지 않고도 효과적인 기계 번역 모델을 구축할 수 있다는 것을 증명**한 것입니다. \n",
      "\n",
      "Transformer는 Attention 메커니즘을 통해 입력 시퀀스의 모든 요소 간의 관계를 효과적으로 학습할 수 있기 때문에, **더 빠른 학습 속도와 높은 병렬 처리 능력**을 제공합니다. \n",
      "\n",
      "실험 결과, Transformer는 기존 최고 성능 모델을 뛰어넘는 결과를 보였으며, 특히 **훈련 시간이 훨씬 단축**되는 것을 확인할 수 있습니다. \n",
      "\n",
      "또한, Transformer는 **기계 번역 외에도 문장 구조 분석과 같은 다른 NLP 작업에도 효과적으로 적용**될 수 있음을 보여주었습니다. \n",
      "\n",
      "이 논문은 **Attention 메커니즘의 잠재력을 보여주는 중요한 연구**이며, 이후 다양한 NLP 모델에 큰 영향을 미쳤습니다. \n",
      "\n",
      "결론적으로, Transformer는 **기계 학습 분야에 혁신적인 변화를 가져온** 중요한 논문입니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_chain = summarize_prompt | gemma2 | StrOutputParser()\n",
    "summary = summarize_chain.invoke(docs[0].page_content)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCaANqOKMpoa"
   },
   "source": [
    "해당 방법은 매우 간단하지만, Context 길이를 넘어서는 경우 에러가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLO3VmBdikKd"
   },
   "source": [
    "## Map-Reduce\n",
    "LangChain의 PyMuPdfLoader를 이용하여 임의의 PDF를 요약해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "14r339tyikKd"
   },
   "outputs": [],
   "source": [
    "# # Password 있는 PDF 열기\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# path_material = './paper-attention.pdf'\n",
    "\n",
    "# pypdf_loader = PyPDFLoader(path_material, password='비밀번호')\n",
    "# material_pages = pypdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BqWN9mrkikKd"
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1455\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m paper_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://arxiv.org/pdf/1706.03762\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 외부 링크에서 PDF 파일을 다운로드하는 코드\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaper_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaper-attention.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./paper-attention.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)>"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import urllib.request\n",
    "\n",
    "paper_URL = \"https://arxiv.org/pdf/1706.03762\"\n",
    "\n",
    "\n",
    "# 외부 링크에서 PDF 파일을 다운로드하는 코드\n",
    "urllib.request.urlretrieve(\n",
    "    paper_URL,\n",
    "    filename=\"paper-attention.pdf\"\n",
    ")\n",
    "path = './paper-attention.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ImhjYgkqikKd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39498"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "loader = PyMuPDFLoader(\"paper-attention.pdf\")\n",
    "# 페이지별로 저장\n",
    "pages = loader.load()\n",
    "\n",
    "# 코퍼스에 모두 결합\n",
    "corpus = Document(page_content='')\n",
    "for page in pages:\n",
    "    corpus.page_content += page.page_content\n",
    "len(corpus.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvhDiGhdMpoa"
   },
   "source": [
    "긴 Context를 처리하기 위해, 전체 코퍼스를 작은 단위로 쪼개 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c5pXmAy-Mpoa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000) #chunk_size는 한 chunkdp 포함될 최대 글자수입니다.\n",
    "document_list = text_splitter.split_documents([corpus])\n",
    "len(document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE34hmK8Mpoa"
   },
   "source": [
    "이후 Map-Reduce와 Refine을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1rP6f8OMpoa"
   },
   "source": [
    "## Map-Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "itfSciDVMpoa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처는 주어진 문장의 모든 단어들 간의 관계를 파악하기 위해 주의 메커니즘만을 사용하여 기존의 순환 신경망이나 합성곱 신경망을 사용하지 않습니다. \n",
      "\n",
      "Transformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다. 인코더는 입력 문장을 벡터 형태로 변환하고, 디코더는 이 벡터를 기반으로 출력 문장을 생성합니다. \n",
      "\n",
      "Transformer는 셀프-어텐션을 통해 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습할 수 있습니다. 이는 기존의 순환 신경망이나 합성곱 신경망에 비해 병렬 처리가 가능하며, 훈련 시간을 크게 단축시킬 수 있습니다. \n",
      "\n",
      "실험 결과, Transformer는 기존의 최고 성능 모델을 능가하는 결과를 보였으며, 특히 기존 모델보다 훨씬 짧은 시간 안에 훈련될 수 있다는 장점을 보여주었습니다. \n",
      "\n",
      "결론적으로, Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처이며, 향후 기계 번역 및 기타 자연어 처리 분야에서 폭넓게 활용될 것으로 기대됩니다. \n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:02,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 1\n",
      "본 논문은 Transformer 모델의 핵심 구성 요소인 Self-Attention 메커니즘을 설명하고, 이를 기반으로 구축된 모델의 장점을 다룹니다. \n",
      "\n",
      "먼저, Scaled Dot-Product Attention 알고리즘을 소개하며, 이는 쿼리, 키, 값을 이용하여 각 단어의 중요도를 계산하는 방식을 설명합니다. 이 알고리즘은 dot product를 이용하여 계산 속도와 공간 효율성을 높였으며, softmax 함수를 통해 각 단어의 가중치를 결정합니다. \n",
      "\n",
      "다음으로, Multi-Head Attention을 통해 여러 관점에서 정보를 동시에 처리할 수 있도록 개선된다고 설명합니다. 각 헤드는 독립적으로 작동하며, 여러 헤드의 결과를 결합하여 더 풍부한 정보를 학습할 수 있도록 합니다. \n",
      "\n",
      "논문에서는 Transformer 모델에서 Self-Attention이 사용되는 세 가지 방식을 제시합니다. 첫째, encoder-decoder attention은 디코더의 각 단어가 인코더의 모든 단어에 대해 주의를 기울일 수 있도록 합니다. 둘째, encoder 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습할 수 있도록 합니다. 셋째, 디코더 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습하면서도 오른쪽으로만 정보를 흐르도록 제한합니다. \n",
      "\n",
      "또한, Positional Encoding을 통해 순서 정보를 모델에 제공한다고 설명합니다. \n",
      "\n",
      "마지막으로, Self-Attention이 Recurrent와 Convolutional layer보다 뛰어난 성능을 보이는 이유를 설명합니다. Self-Attention은 모든 단어 간의 관계를 효율적으로 학습할 수 있으며, Long-range dependency를 학습하는 데 유리합니다.\n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:02<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2\n",
      "본 논문은 Transformer라는 새로운 신경망 아키텍처를 소개하며, 기존의 순환 신경망(RNN) 기반 기계 번역 모델보다 우수한 성능을 보여줍니다. Transformer는 자기 주의(self-attention) 메커니즘을 사용하여 입력 시퀀스의 모든 요소 간의 관계를 효율적으로 학습할 수 있습니다. 이는 RNN보다 훨씬 빠른 연산 속도를 제공하며, 특히 긴 문장을 처리하는 데 유리합니다. \n",
      "\n",
      "논문에서는 Transformer의 구조와 동작 원리를 자세히 설명하고, 기존 모델들과의 비교 실험을 통해 성능 우월성을 입증합니다. 특히, 영어-독일어 및 영어-프랑스어 번역 작업에서 Transformer는 기존 최고 성능 모델을 능가하는 BLEU 점수를 달성했습니다. 또한, Transformer는 구성 요소별 변화를 통해 각 요소의 중요성을 분석하고, 다른 작업인 영어 문장 구조 분석에도 효과적으로 적용될 수 있음을 보여줍니다. \n",
      "\n",
      "결론적으로, Transformer는 기계 번역 및 관련 분야에서 새로운 기준을 제시하는 강력한 모델이며, 자기 주의 메커니즘을 활용한 효율적이고 강력한 학습 능력을 보여줍니다.\n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:03<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3\n",
      "본 논문은 Transformer라는 새로운 시퀀스 전환 모델을 소개하며, 이 모델은 주로 사용되는 순환적 인코더-디코더 아키텍처 대신 완전히 Attention 기반으로 구축되었습니다. Transformer는 번역 작업에서 순환적 또는 합성곱 신경망 기반 아키텍처보다 훨씬 빠르게 학습될 수 있습니다. WMT 2014 영어-독일어 및 영어-프랑스어 번역 작업에서 기존의 모든 모델을 능가하는 새로운 성능 기록을 달성했습니다. 특히, Transformer는 40,000개의 문장으로 구성된 WSJ 데이터셋만을 사용하여 학습하더라도 BerkeleyParser와 같은 기존 모델보다 우수한 성능을 보였습니다. 또한, Transformer는 1700만 개의 문장으로 구성된 semi-supervised 데이터셋을 사용하여 학습했을 때 더욱 향상된 성능을 보였습니다. \n",
      "\n",
      "본 논문은 Transformer 모델의 구조와 학습 방법을 설명하고, WMT 2014 번역 작업에서의 성능을 평가합니다. \n",
      "\n",
      "Transformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 멀티헤드 어텐션 계층과 Feed-Forward 네트워크로 구성됩니다. \n",
      "\n",
      "학습 과정에서 Transformer는 주어진 문장의 각 단어에 대한 주변 단어들과의 관계를 학습하여 문맥을 이해합니다. \n",
      "\n",
      "본 논문은 Transformer가 순환적 모델보다 빠르게 학습되고 더 높은 성능을 달성할 수 있다는 것을 보여주며, 향후 자연어 처리 분야에서 널리 적용될 것으로 기대됩니다. \n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4\n",
      "본 논문은 인공지능 모델에서 주목 메커니즘의 작동 방식을 이해하기 위해 다양한 시각화 기법을 사용하여 주목 메커니즘의 내부 구조를 분석하고 그 작동 원리를 탐구합니다. 특히, 주목 메커니즘이 문장 내 긴 거리 의존성을 따라가는 방식, 어휘 해석, 그리고 문장 구조를 이해하는 데 어떻게 기여하는지 보여줍니다. 논문은 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 이해하고 처리하는 과정을 더 명확하게 이해할 수 있도록 돕고, 향후 주목 메커니즘의 개선 및 발전을 위한 방향을 제시합니다. \n",
      "\n",
      "* 논문은 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 이해하는 과정을 탐구합니다.\n",
      "* 주목 메커니즘은 긴 거리 의존성을 따라가는 방식을 보여주며, 문장 내 멀리 떨어진 단어들 간의 관계를 파악하는 데 도움을 줍니다.\n",
      "* 주목 메커니즘은 어휘 해석에도 기여하며, 특정 단어에 대한 주목 강도를 통해 단어의 의미를 더 정확하게 파악합니다.\n",
      "* 논문은 주목 메커니즘이 문장 구조를 이해하는 데에도 중요한 역할을 한다는 것을 보여줍니다.\n",
      "* 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 처리하는 방식을 더 명확하게 이해할 수 있습니다.\n",
      "* 이러한 시각화 기법은 향후 주목 메커니즘의 개선 및 발전을 위한 방향을 제시합니다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Map 과정 : 각 문서에 대해 요약을 생성합니다. -> Long Context 인 경우, 균일하게 분할하여 요약하고 다시 합치는 방법으로 성능 개선\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''주어진 논문의 내용을 읽고 한국어로 요약하세요.\n",
    "요약은 1개의 문단과 문단별 6개의 문장으로 작성하세요.\n",
    "답변은 한국어로 작성하세요.\n",
    "같은 내용을 반복하지 마세요.\n",
    "'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "map_chain  = map_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "raw_summaries = []\n",
    "for i in tqdm(range(len(document_list))):\n",
    "    response = map_chain.invoke(document_list[i].page_content)\n",
    "    raw_summaries.append(response)\n",
    "    print('')\n",
    "    print('#',i)\n",
    "    print(response)\n",
    "    print('===========================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처는 주어진 문장의 모든 단어들 간의 관계를 파악하기 위해 주의 메커니즘만을 사용하여 기존의 순환 신경망이나 합성곱 신경망을 사용하지 않습니다. \\n\\nTransformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다. 인코더는 입력 문장을 벡터 형태로 변환하고, 디코더는 이 벡터를 기반으로 출력 문장을 생성합니다. \\n\\nTransformer는 셀프-어텐션을 통해 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습할 수 있습니다. 이는 기존의 순환 신경망이나 합성곱 신경망에 비해 병렬 처리가 가능하며, 훈련 시간을 크게 단축시킬 수 있습니다. \\n\\n실험 결과, Transformer는 기존의 최고 성능 모델을 능가하는 결과를 보였으며, 특히 기존 모델보다 훨씬 짧은 시간 안에 훈련될 수 있다는 장점을 보여주었습니다. \\n\\n결론적으로, Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처이며, 향후 기계 번역 및 기타 자연어 처리 분야에서 폭넓게 활용될 것으로 기대됩니다. \\n\\n\\n\",\n",
       " '본 논문은 Transformer 모델의 핵심 구성 요소인 Self-Attention 메커니즘을 설명하고, 이를 기반으로 구축된 모델의 장점을 다룹니다. \\n\\n먼저, Scaled Dot-Product Attention 알고리즘을 소개하며, 이는 쿼리, 키, 값을 이용하여 각 단어의 중요도를 계산하는 방식을 설명합니다. 이 알고리즘은 dot product를 이용하여 계산 속도와 공간 효율성을 높였으며, softmax 함수를 통해 각 단어의 가중치를 결정합니다. \\n\\n다음으로, Multi-Head Attention을 통해 여러 관점에서 정보를 동시에 처리할 수 있도록 개선된다고 설명합니다. 각 헤드는 독립적으로 작동하며, 여러 헤드의 결과를 결합하여 더 풍부한 정보를 학습할 수 있도록 합니다. \\n\\n논문에서는 Transformer 모델에서 Self-Attention이 사용되는 세 가지 방식을 제시합니다. 첫째, encoder-decoder attention은 디코더의 각 단어가 인코더의 모든 단어에 대해 주의를 기울일 수 있도록 합니다. 둘째, encoder 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습할 수 있도록 합니다. 셋째, 디코더 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습하면서도 오른쪽으로만 정보를 흐르도록 제한합니다. \\n\\n또한, Positional Encoding을 통해 순서 정보를 모델에 제공한다고 설명합니다. \\n\\n마지막으로, Self-Attention이 Recurrent와 Convolutional layer보다 뛰어난 성능을 보이는 이유를 설명합니다. Self-Attention은 모든 단어 간의 관계를 효율적으로 학습할 수 있으며, Long-range dependency를 학습하는 데 유리합니다.\\n\\n\\n',\n",
       " '본 논문은 Transformer라는 새로운 신경망 아키텍처를 소개하며, 기존의 순환 신경망(RNN) 기반 기계 번역 모델보다 우수한 성능을 보여줍니다. Transformer는 자기 주의(self-attention) 메커니즘을 사용하여 입력 시퀀스의 모든 요소 간의 관계를 효율적으로 학습할 수 있습니다. 이는 RNN보다 훨씬 빠른 연산 속도를 제공하며, 특히 긴 문장을 처리하는 데 유리합니다. \\n\\n논문에서는 Transformer의 구조와 동작 원리를 자세히 설명하고, 기존 모델들과의 비교 실험을 통해 성능 우월성을 입증합니다. 특히, 영어-독일어 및 영어-프랑스어 번역 작업에서 Transformer는 기존 최고 성능 모델을 능가하는 BLEU 점수를 달성했습니다. 또한, Transformer는 구성 요소별 변화를 통해 각 요소의 중요성을 분석하고, 다른 작업인 영어 문장 구조 분석에도 효과적으로 적용될 수 있음을 보여줍니다. \\n\\n결론적으로, Transformer는 기계 번역 및 관련 분야에서 새로운 기준을 제시하는 강력한 모델이며, 자기 주의 메커니즘을 활용한 효율적이고 강력한 학습 능력을 보여줍니다.\\n\\n\\n',\n",
       " '본 논문은 Transformer라는 새로운 시퀀스 전환 모델을 소개하며, 이 모델은 주로 사용되는 순환적 인코더-디코더 아키텍처 대신 완전히 Attention 기반으로 구축되었습니다. Transformer는 번역 작업에서 순환적 또는 합성곱 신경망 기반 아키텍처보다 훨씬 빠르게 학습될 수 있습니다. WMT 2014 영어-독일어 및 영어-프랑스어 번역 작업에서 기존의 모든 모델을 능가하는 새로운 성능 기록을 달성했습니다. 특히, Transformer는 40,000개의 문장으로 구성된 WSJ 데이터셋만을 사용하여 학습하더라도 BerkeleyParser와 같은 기존 모델보다 우수한 성능을 보였습니다. 또한, Transformer는 1700만 개의 문장으로 구성된 semi-supervised 데이터셋을 사용하여 학습했을 때 더욱 향상된 성능을 보였습니다. \\n\\n본 논문은 Transformer 모델의 구조와 학습 방법을 설명하고, WMT 2014 번역 작업에서의 성능을 평가합니다. \\n\\nTransformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 멀티헤드 어텐션 계층과 Feed-Forward 네트워크로 구성됩니다. \\n\\n학습 과정에서 Transformer는 주어진 문장의 각 단어에 대한 주변 단어들과의 관계를 학습하여 문맥을 이해합니다. \\n\\n본 논문은 Transformer가 순환적 모델보다 빠르게 학습되고 더 높은 성능을 달성할 수 있다는 것을 보여주며, 향후 자연어 처리 분야에서 널리 적용될 것으로 기대됩니다. \\n\\n\\n',\n",
       " '본 논문은 인공지능 모델에서 주목 메커니즘의 작동 방식을 이해하기 위해 다양한 시각화 기법을 사용하여 주목 메커니즘의 내부 구조를 분석하고 그 작동 원리를 탐구합니다. 특히, 주목 메커니즘이 문장 내 긴 거리 의존성을 따라가는 방식, 어휘 해석, 그리고 문장 구조를 이해하는 데 어떻게 기여하는지 보여줍니다. 논문은 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 이해하고 처리하는 과정을 더 명확하게 이해할 수 있도록 돕고, 향후 주목 메커니즘의 개선 및 발전을 위한 방향을 제시합니다. \\n\\n* 논문은 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 이해하는 과정을 탐구합니다.\\n* 주목 메커니즘은 긴 거리 의존성을 따라가는 방식을 보여주며, 문장 내 멀리 떨어진 단어들 간의 관계를 파악하는 데 도움을 줍니다.\\n* 주목 메커니즘은 어휘 해석에도 기여하며, 특정 단어에 대한 주목 강도를 통해 단어의 의미를 더 정확하게 파악합니다.\\n* 논문은 주목 메커니즘이 문장 구조를 이해하는 데에도 중요한 역할을 한다는 것을 보여줍니다.\\n* 주목 메커니즘의 시각화를 통해 인공지능 모델이 언어를 처리하는 방식을 더 명확하게 이해할 수 있습니다.\\n* 이러한 시각화 기법은 향후 주목 메커니즘의 개선 및 발전을 위한 방향을 제시합니다.\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ckS-TZVsMpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Transformer: 자기 주의를 통한 혁신적인 신경망 아키텍처\n",
      "\n",
      "본 논문은 자연어 처리 분야에서 혁신적인 성과를 보여주는 새로운 신경망 아키텍처인 Transformer를 소개합니다. Transformer는 기존의 순환 신경망이나 합성곱 신경망을 대체하여 자기 주의(self-attention) 메커니즘만을 사용하여 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습합니다. \n",
      "\n",
      "**핵심 내용:**\n",
      "\n",
      "* Transformer는 인코더와 디코더로 구성되며, 각각은 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다.\n",
      "* 셀프-어텐션을 통해 Transformer는 병렬 처리가 가능하며, 훈련 시간을 크게 단축시킬 수 있습니다.\n",
      "* 실험 결과, Transformer는 기존 모델을 능가하는 성능을 보였으며, 특히 빠른 훈련 속도를 보여주었습니다.\n",
      "* Transformer는 기계 번역뿐만 아니라 문장 구조 분석 등 다양한 자연어 처리 작업에 효과적으로 적용될 수 있습니다.\n",
      "\n",
      "**결론:**\n",
      "\n",
      "Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처이며, 자기 주의 메커니즘을 통해 자연어 처리 분야에서 새로운 기준을 제시합니다. 향후 Transformer는 기계 번역, 질의응답, 텍스트 요약 등 다양한 분야에서 폭넓게 활용될 것으로 기대됩니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reduce 과정 : 각 문서의 요약을 하나로 합칩니다.\n",
    "reduce_prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    ('system', '''\n",
    "Generate a summary of the following text that includes the following elements:\n",
    "\n",
    "* A title that accurately reflects the content of the text.\n",
    "* An introduction paragraph that provides an overview of the topic.\n",
    "* Bullet points that list the key points of the text.\n",
    "* A conclusion paragraph that summarizes the main points of the text.\n",
    "\n",
    "Answer in Korean.\n",
    "'''),\n",
    "    ('user', '''{text}\n",
    "---\n",
    "요약(In Korean):\n",
    "''')])\n",
    "\n",
    "reduce_chain = reduce_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "summary = reduce_chain.invoke('\\n---\\n'.join(raw_summaries))\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi84F2cYMpoa"
   },
   "source": [
    "## Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZfANrVtMpoa"
   },
   "source": [
    "Refine은 청크를 순서대로 참고하며, 매 시점 요약문을 작성합니다.   \n",
    "요약문과 새로운 청크를 비교하여, 요약문을 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7dee-KnHMpob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "* 논문은 기존의 순환 신경망 기반 모델의 한계점을 지적하며, 특히 길어지는 입력/출력 시퀀스에서 병렬 처리의 어려움을 언급합니다.\n",
      "* Transformer는 자기 주의 메커니즘을 기반으로 하며, 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습할 수 있습니다.\n",
      "* Transformer는 인코더와 디코더 스택으로 구성되며, 각 스택은 여러 개의 자기 주의 및 점별 밀집 연결 계층으로 이루어져 있습니다.\n",
      "* 디코더는 인코더의 출력에 대한 주의 메커니즘을 추가하여 이전에 생성된 출력을 활용하여 다음 출력을 생성합니다.\n",
      "* 논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서도 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 청크 순서대로 각 청크들을 요약하고, 앞부분 청크 요약과 현재 청크를 연결하여 요약을 업데이트하며 진행한다.\n",
    "# 시간은 오래 걸릴 수 있으나, 청크 업데이트가 잦은 경우에 사용\n",
    "first_summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''당신은 인공지능 전문가입니다.\n",
    "주어진 논문의 내용을 읽고 한국어로 요약하세요.\n",
    "요약은 1개의 문단과 문단별 5개의 문장으로 작성하세요.\n",
    "답변은 한국어로 작성하세요.'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "\n",
    "\n",
    "X = first_summarize_prompt.format_messages(text=document_list[0])\n",
    "\n",
    "intermediate_summary = gemma2.invoke(X).content\n",
    "print(intermediate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bBpA1i76Mpob"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:08<00:25,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지고 입력을 처리하여 다양한 정보를 학습합니다. \n",
      "\n",
      "또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 제공합니다.  입력 토큰에 각각의 위치에 대한 고유한 벡터를 추가하여 시퀀스의 순서를 학습할 수 있도록 합니다. \n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 짧은 경로로 정보를 전달할 수 있어 장거리 의존성을 학습하는 데 유리합니다. \n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:21<00:21, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지고 입력을 처리하여 다양한 정보를 학습합니다. 또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 제공합니다.  입력 토큰에 각각의 위치에 대한 고유한 벡터를 추가하여 시퀀스의 순서를 학습할 수 있도록 합니다.\n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 짧은 경로로 정보를 전달할 수 있어 장거리 의존성을 학습하는 데 유리합니다. \n",
      "\n",
      "Transformer는 자체적인 attention 메커니즘을 사용하여 RNN 기반 모델보다 빠른 학습 속도를 보이며, 특히 긴 문장의 정보 전달에 유리합니다. 또한, Transformer는 병렬 처리 성능이 뛰어나기 때문에 RNN 기반 모델보다 훨씬 빠른 학습 속도를 보입니다. \n",
      "\n",
      "실험 결과, Transformer는 기존 모델들보다 높은 번역 성능을 달성했으며, 특히 영어-독일어 번역에서 2.0 BLEU 이상의 성능 향상을 보였습니다. 또한, Transformer는 영어-프랑스어 번역에서도 기존 모델들보다 높은 성능을 보였으며, 훈련 비용이 1/4로 줄어들었습니다.\n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:37<00:13, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지고 입력을 처리하여 다양한 정보를 학습합니다. 또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 제공합니다.  입력 토큰에 각각의 위치에 대한 고유한 벡터를 추가하여 시퀀스의 순서를 학습할 수 있도록 합니다.\n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 짧은 경로로 정보를 전달할 수 있어 장거리 의존성을 학습하는 데 유리합니다. \n",
      "\n",
      "Transformer는 Penn Treebank 데이터셋을 사용하여 영어 문장 구조 분석에도 적용되었으며, 기존 모델들과 비교하여 우수한 성능을 보였습니다. 또한, Transformer는 훈련 데이터의 크기가 작더라도 좋은 성능을 보이는 semi-supervised 학습 방식에서도 효과적이었습니다. \n",
      "\n",
      "실험 결과, Transformer는 기존 모델들보다 높은 번역 성능을 달성했으며, 특히 영어-독일어 번역에서 2.0 BLEU 이상의 성능 향상을 보였습니다. 또한, Transformer는 영어-프랑스어 번역에서도 기존 모델들보다 높은 성능을 보였으며, 훈련 비용이 1/4로 줄어들었습니다. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:48<00:00, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지고 입력을 처리하여 다양한 정보를 학습합니다. 또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 제공합니다.  입력 토큰에 각각의 위치에 대한 고유한 벡터를 추가하여 시퀀스의 순서를 학습할 수 있도록 합니다.\n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 짧은 경로로 정보를 전달할 수 있어 장거리 의존성을 학습하는 데 유리합니다. \n",
      "\n",
      "Transformer는 Penn Treebank 데이터셋을 사용하여 영어 문장 구조 분석에도 적용되었으며, 기존 모델들과 비교하여 우수한 성능을 보였습니다. 또한, Transformer는 훈련 데이터의 크기가 작더라도 좋은 성능을 보이는 semi-supervised 학습 방식에서도 효과적이었습니다. \n",
      "\n",
      "실험 결과, Transformer는 기존 모델들보다 높은 번역 성능을 달성했으며, 특히 영어-독일어 번역에서 2.0 BLEU 이상의 성능 향상을 보였습니다. 또한, Transformer는 영어-프랑스어 번역에서도 기존 모델들보다 높은 성능을 보였으며, 훈련 비용이 1/4로 줄어들었습니다. \n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Refine Prompt\n",
    "\n",
    "refine_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''당신은 인공지능 전문가입니다.\n",
    "논문의 현재 시점까지의 한국어 요약이 주어집니다.\n",
    "이를 읽고, 새롭게 주어지는 내용과 비교하여 한국어 요약을 보완하거나 수정하세요.\n",
    "전체 요약은 10문장 이내로 작성하세요.\n",
    "'''),\n",
    "    ('user', '''현재 시점까지의 요약: {previous_summary}\n",
    "---\n",
    "새로운 내용: {new_text}''')])\n",
    "\n",
    "\n",
    "refine_chain = refine_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "for i in tqdm(range(1, len(document_list))):\n",
    "    intermediate_summary = refine_chain.invoke(\n",
    "        {'previous_summary':intermediate_summary,\n",
    "         'new_text':document_list[i].page_content})\n",
    "    print('')\n",
    "    print(intermediate_summary)\n",
    "    print('=======================')\n",
    "# 길이를 지정하지 않으면 오래 걸릴 수 있습니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
